const { GoogleGenerativeAI } = require('@google/generative-ai');
const SupabaseClient = require('./supabase-client');
const config = require('./config');

async function testWorkingArticle() {
    const genAI = new GoogleGenerativeAI(config.gemini.apiKey);
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    const supabase = new SupabaseClient();
    
    console.log('ğŸ” Testing Article Integration with Working Content\n');
    
    try {
        // Find the tweet with the NY Post article
        const { data: articles } = await supabase.supabase
            .from('article_content')
            .select('*')
            .eq('url', 'https://nypost.com/2025/06/02/sports/olympic-boxer-imane-khelifs-leaked-lab-results-offer-new-evidence-about-her-biological-sex/');
            
        if (!articles || articles.length === 0) {
            console.log('âŒ No NY Post article found');
            return;
        }
        
        const article = articles[0];
        console.log(`ğŸ“„ Found article: ${article.title}`);
        console.log(`ğŸ“ Word count: ${article.word_count}`);
        console.log(`ğŸ“ Content preview: ${article.content.substring(0, 200)}...\n`);
        
        // Find the tweet that links to this article
        const { data: tweets } = await supabase.supabase
            .from('jk_rowling_posts')
            .select('*')
            .eq('junkipedia_id', article.tweet_id);
            
        if (!tweets || tweets.length === 0) {
            console.log('âŒ No tweet found for this article');
            return;
        }
        
        const tweet = tweets[0];
        console.log(`ğŸ” Tweet ${tweet.junkipedia_id}:`);
        console.log(`ğŸ“ Content: ${tweet.content}\n`);
        
        // Test AI analysis with article content
        console.log('ğŸ¤– Testing AI analysis with article content...\n');
        
        const prompt = `
Tweet Content: "${tweet.content}"

Linked Article: "${article.title}"
Article Content: "${article.content.substring(0, 1000)}..."

Please analyze this tweet AND the linked article for potentially transphobic content. Consider:
1. Language that denies trans people's identities
2. Misgendering or deadnaming
3. Harmful stereotypes about trans people
4. Content that could contribute to discrimination or violence
5. Rhetoric that questions trans rights or access to healthcare
6. Language that frames trans people as threats or dangerous

Provide your analysis in the following JSON format:
{
  "is_potentially_transphobic": true/false,
  "confidence_level": "high/medium/low",
  "concerns": ["list of specific concerns"],
  "explanation": "detailed explanation",
  "severity": "high/medium/low",
  "recommendations": ["suggestions"],
  "tweet_analysis": "analysis of tweet content",
  "article_analysis": "analysis of article content",
  "combined_analysis": "combined analysis of both",
  "articles_analyzed": 1
}
`;

        const result = await model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();
        
        console.log('ğŸ“Š AI Response:');
        console.log(text);
        
        // Try to parse JSON
        try {
            const jsonMatch = text.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                const analysis = JSON.parse(jsonMatch[0]);
                console.log('\nâœ… Successfully parsed analysis:');
                console.log(`   ğŸš¨ Potentially transphobic: ${analysis.is_potentially_transphobic}`);
                console.log(`   ğŸ“Š Confidence: ${analysis.confidence_level}`);
                console.log(`   âš ï¸  Severity: ${analysis.severity}`);
                console.log(`   ğŸ“„ Articles analyzed: ${analysis.articles_analyzed}`);
            }
        } catch (parseError) {
            console.log('\nâŒ Error parsing JSON response');
        }
        
    } catch (error) {
        console.error('âŒ Error:', error);
    }
}

testWorkingArticle().catch(console.error);
